# Принцип работы программы

Сначала генерируются матрицы, потом, с помощью **MPI_Scatter** левая матрица разбивается на строки и отправляется в каждый поток по отдельности. В зависимости от размерности матрицы и количества потоков матрица может разбиваться на группы строк. Также в потоки отправляются данные и об остальных матрицах, которые участвуют в произведении, с помощью **MPI_Bcast**. Вычисляются элементы матрицы произведение, и с помощью **MPI_Gather** собираются в один цельный массив.
Данный алгоритм работает для квадратных матриц, размерность которых равна степени двойки. Также для распараллеливания матрицы надо хранить в виде одномерного массива.

# Сравнение времени выполнения последовательного и параллельного алгоритмов в зависимости от размерности матрицы 

RANKS: 8
Matrix size: 8
Seq_time: 0.000006
Par time: 0.000130

RANKS: 8
Matrix size: 16
Seq_time: 0.000042
Par time: 0.000189

RANKS: 8
Matrix size: 32
Seq_time: 0.000304
Par time: 0.000324

RANKS: 8
Matrix size: 64
Seq_time: 0.002501
Par time: 0.000844

RANKS: 8
Matrix size: 128
Seq_time: 0.018756
Par time: 0.003621

RANKS: 8
Matrix size: 256
Seq_time: 0.129059
Par time: 0.025391

RANKS: 8
Matrix size: 512
Seq_time: 1.161707
Par time: 0.197321

# Логи выполнения программы на разном числе процессоров

RANKS: 16
Matrix size: 512
Seq_time: 1.629994
Par time: 0.203756

RANKS: 32
Matrix size: 512
Seq_time: 1.514438
Par time: 0.219018

RANKS: 64
Matrix size: 512
Seq_time: 1.646173
Par time: 0.349065
